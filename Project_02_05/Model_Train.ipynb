{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.4.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.4.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import string\n",
    "import warnings\n",
    "import missingno\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import cufflinks as cf\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import gamma\n",
    "from numpy.random import multivariate_normal\n",
    "from scipy.stats import multivariate_t\n",
    "from scipy.stats import f\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "cf.go_offline(connected = True)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import cufflinks as cf\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import gamma\n",
    "from numpy.random import multivariate_normal\n",
    "from scipy.stats import multivariate_t\n",
    "from scipy.stats import f\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno\n",
    "\n",
    "\n",
    "cf.go_offline(connected = True)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor \n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import string\n",
    "import warnings\n",
    "import missingno\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np # 각 모델에서 내부적으로 관련 라이브러리 사용 가능\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor         # 1. K-Nearest Neighbor(KNN)\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor                   # 4. Decision Tree\n",
    "from sklearn.ensemble import RandomForestRegressor   # 5. Random Forest\n",
    "from sklearn.ensemble import ExtraTreesRegressor             # 6. Extra Tree\n",
    "from sklearn.ensemble import GradientBoostingRegressor  # 7. GBM\n",
    "\n",
    "from xgboost import XGBRFRegressor                                     # 9. XGBoost\n",
    "from lightgbm import LGBMRegressor                                 # 10. LightGBM\n",
    "import warnings\n",
    "from sklearn.model_selection import TimeSeriesSplit \n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np # 각 모델에서 내부적으로 관련 라이브러리 사용 가능\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier             # 1. K-Nearest Neighbor(KNN)\n",
    "from sklearn.linear_model import LogisticRegression            # 2. Logistic Regression\n",
    "from sklearn.svm import SVC                                                # 3. SVC\n",
    "from sklearn.tree import DecisionTreeClassifier                   # 4. Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier       # 5. Random Forest\n",
    "from sklearn.ensemble import ExtraTreesClassifier  # 6. ExtraTrees\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier # 7. GBM\n",
    "from sklearn.naive_bayes import GaussianNB                     # 8. GaussianNB\n",
    "from xgboost import XGBClassifier                                     # 9. XGBoost\n",
    "from lightgbm import LGBMClassifier                                 # 10. LightGBM\n",
    "import warnings\n",
    "from sklearn.svm import SVR  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_importance = pd.read_csv('물품_train_importance_1.csv',encoding ='cp949').iloc[:,1:]\n",
    "train_answer = pd.read_csv('물품_y_train_1.csv',encoding ='cp949').iloc[:,1:]\n",
    "\n",
    "# test_importance = pd.read_csv('물품_test_importance_1.csv',encoding ='cp949').iloc[:,1:]\n",
    "# test_answer = pd.read_csv('물품_y_test.csv',encoding = 'cp949').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minus(row):\n",
    "    for i in row.values[0]:\n",
    "        if i < 0:\n",
    "            return row\n",
    "        \n",
    "minus(train_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(predicted,real):\n",
    "    sum=0.0\n",
    "    for x in range(len(predicted)):\n",
    "        if predicted[x]<0 or real[x]<0: #check for negative values\n",
    "            continue\n",
    "        p = np.log(predicted[x]+1)\n",
    "        r = np.log(real[x]+1)\n",
    "        sum = sum + (p - r)**2\n",
    "    return (sum/len(predicted))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 810 out of 810 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:46:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"min_samples_leaf\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "{'learning_rate': 0.02, 'max_depth': 4, 'min_samples_leaf': 12, 'n_estimators': 200, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [200, 500, 750]\n",
    "max_depth = [4, 5, 6]\n",
    "min_samples_leaf = [12, 15]\n",
    "learning_rate = [0.02, 0.05, 0.1]\n",
    "subsample = [0.6, 0.7, 0.8]\n",
    "\n",
    "hyperparams = {'n_estimators': n_estimators, 'max_depth': max_depth, \n",
    "                    'min_samples_leaf': min_samples_leaf,\n",
    "                    'learning_rate': learning_rate, 'subsample': subsample\n",
    "              }\n",
    "\n",
    "\n",
    "XGB_grid = GridSearchCV(estimator = XGBRegressor(), param_grid = hyperparams, \n",
    "                verbose=True, scoring='mean_squared_error', cv=tscv, n_jobs=-1,)\n",
    "# XGB_grid\n",
    "XGB_grid.fit(train_importance, train_answer)\n",
    "print(XGB_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XGBRegressor_Model_Train.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import joblib\n",
    "\n",
    "# joblib.dump(XGB_grid, 'XGBRegressor_Model_Train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 12, 'min_samples_leaf': 6, 'min_samples_split': 5, 'n_estimators': 800}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_estimators = [800, 1000, 1200]\n",
    "max_depth = [10, 12, 15]\n",
    "min_samples_split = [4, 5, 6]\n",
    "min_samples_leaf = [4, 5, 6]\n",
    "\n",
    "hyperparams = {'n_estimators': n_estimators, 'max_depth': max_depth, \n",
    "               'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "random_grid = GridSearchCV(estimator = RandomForestRegressor(), param_grid = hyperparams, \n",
    "                verbose=True, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "\n",
    "random_grid.fit(train_importance, train_answer)\n",
    "print(random_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_grid_Model_Train.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import joblib\n",
    "\n",
    "# joblib.dump(random_grid, 'random_grid_Model_Train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   46.5s\n",
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'min_samples_leaf': 6, 'min_samples_split': 5, 'n_estimators': 800}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_estimators = [800, 1000, 1200]\n",
    "max_depth = [10, 12, 15]\n",
    "min_samples_split = [4, 5, 6]\n",
    "min_samples_leaf = [4, 5, 6]\n",
    "\n",
    "hyperparams = {'n_estimators': n_estimators, 'max_depth': max_depth, \n",
    "               'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "random_grid_extra = GridSearchCV(estimator = ExtraTreesRegressor(), param_grid = hyperparams, \n",
    "                verbose=True, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "\n",
    "random_grid_extra.fit(train_importance, train_answer)\n",
    "print(random_grid_extra.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_grid_extra_Model_Train.pkl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import joblib\n",
    "\n",
    "# joblib.dump(random_grid_extra, 'random_grid_extra_Model_Train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
