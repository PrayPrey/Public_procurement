{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import string\n",
    "import warnings\n",
    "import missingno\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import cufflinks as cf\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import gamma\n",
    "from numpy.random import multivariate_normal\n",
    "from scipy.stats import multivariate_t\n",
    "from scipy.stats import f\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "cf.go_offline(connected = True)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import cufflinks as cf\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import gamma\n",
    "from numpy.random import multivariate_normal\n",
    "from scipy.stats import multivariate_t\n",
    "from scipy.stats import f\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno\n",
    "\n",
    "\n",
    "cf.go_offline(connected = True)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor \n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import string\n",
    "import warnings\n",
    "import missingno\n",
    "from scipy.stats import f\n",
    "import scipy\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_용역 = pd.read_csv('용역_Proj_02_06.csv').iloc[:,1:]\n",
    "df_공사 = pd.read_csv('공사_Proj_02_06.csv').iloc[:,1:]\n",
    "df_물품 = pd.read_csv('물품_Proj_02_06.csv').iloc[:,1:]\n",
    "\n",
    "df_용역['공고게시일자'] = pd.to_datetime(df_용역['공고게시일자'])\n",
    "df_공사['공고게시일자'] = pd.to_datetime(df_공사['공고게시일자'])\n",
    "df_물품['공고게시일자'] = pd.to_datetime(df_물품['공고게시일자'])\n",
    "\n",
    "df_물품_추정가격 = df_물품.groupby(pd.Grouper(key = '공고게시일자', freq = '1W')).sum()['추정가격']\n",
    "df_공사_추정가격 = df_공사.groupby(pd.Grouper(key = '공고게시일자', freq = '1W')).sum()['추정가격']\n",
    "df_용역_추정가격 = df_용역.groupby(pd.Grouper(key = '공고게시일자', freq = '1W')).sum()['추정가격']\n",
    "\n",
    "df = pd.merge(df_용역_추정가격,df_공사_추정가격,left_index= True, right_index=True, how = 'outer')\n",
    "df_total_추정가격 = pd.merge(df,df_물품_추정가격,left_index= True, right_index=True , how = 'outer')\n",
    "\n",
    "df_total_추정가격.columns = ['용역','공사','물품']\n",
    "\n",
    "df_test = df_total_추정가격.reset_index()[['용역']].reset_index()\n",
    "\n",
    "df_물품_ZZ = df_물품[df_물품['수요기관코드'] == 'B500001']\n",
    "df_용역_ZZ = df_용역[df_용역['수요기관코드'] == 'B500001']\n",
    "df_공사_ZZ = df_공사[df_공사['수요기관코드'] == 'B500001']\n",
    "\n",
    "df_물품_ZZ_grouper = df_물품_ZZ.groupby(pd.Grouper(key = '공고게시일자', freq = '1W')).sum()[['추정가격']]\n",
    "df_용역_ZZ_grouper = df_용역_ZZ.groupby(pd.Grouper(key = '공고게시일자', freq = '1W')).sum()[['추정가격']]\n",
    "df_공사_ZZ_grouper = df_공사_ZZ.groupby(pd.Grouper(key = '공고게시일자', freq = '1W')).sum()[['추정가격']]\n",
    "\n",
    "df_물품_ZZ_grouper.reset_index()[['추정가격']]\n",
    "df_용역_ZZ_grouper.reset_index()[['추정가격']]\n",
    "df_공사_ZZ_grouper.reset_index()[['추정가격']]\n",
    "\n",
    "df_test = pd.merge(df_물품_ZZ_grouper.reset_index()[['추정가격']],df_용역_ZZ_grouper.reset_index()[['추정가격']],left_index = True, right_index =True, how = 'outer')\n",
    "df_test_2 = pd.merge(df_test,df_용역_ZZ_grouper.reset_index()[['추정가격']],left_index = True, right_index =True, how = 'outer')\n",
    "\n",
    "df_test.columns = ['물품','용역']\n",
    "df_test_2.columns = ['물품','용역','공사']\n",
    "\n",
    "df_test = df_test.fillna(0).copy()\n",
    "df_test_2 = df_test_2.fillna(0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import robust_scale\n",
    "\n",
    "transformer  = RobustScaler()\n",
    "transformer.fit(df_test)\n",
    "df_test = transformer.transform(df_test)\n",
    "\n",
    "transformer  = RobustScaler()\n",
    "transformer.fit(df_test_2)\n",
    "df_test_2 = transformer.transform(df_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17349953467545662"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 적절한 gamma 값 ; sklearn의 svm에서 기본 default값 계산을 참조함 (2차원)\n",
    "1/ (2 *np.array(df_test).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15141959537014263"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 적절한 gamma 값 ; sklearn의 svm에서 기본 default값 계산을 참조함 (3차원)\n",
    "1/ (2 *np.array(df_test_2).var()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/USER/Documents/Jupyter Notebook/public_procurement/Project_02_15\\SVDD-Python-master/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 일단 2차원(물품 / 용역) 만 보기로 하였다. 왜냐하면, 시각화 시켜서 이해하기에는 2차원이 적당하기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.580383</td>\n",
       "      <td>-0.476234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.581019</td>\n",
       "      <td>-0.476234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.672586</td>\n",
       "      <td>-0.476234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.613643</td>\n",
       "      <td>-0.476234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.352531</td>\n",
       "      <td>-0.476234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>5.311560</td>\n",
       "      <td>-0.476234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>4.543185</td>\n",
       "      <td>-0.476234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2.616027</td>\n",
       "      <td>-0.476234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>-0.325642</td>\n",
       "      <td>-0.476234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>-0.600180</td>\n",
       "      <td>-0.476234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "0   -0.580383 -0.476234\n",
       "1   -0.581019 -0.476234\n",
       "2   -0.672586 -0.476234\n",
       "3   -0.613643 -0.476234\n",
       "4   -0.352531 -0.476234\n",
       "..        ...       ...\n",
       "202  5.311560 -0.476234\n",
       "203  4.543185 -0.476234\n",
       "204  2.616027 -0.476234\n",
       "205 -0.325642 -0.476234\n",
       "206 -0.600180 -0.476234\n",
       "\n",
       "[207 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 2 required positional arguments: 'bs_size' and 'alpha'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e564c5916085>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# fit the SVDD model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0msvdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# predict the label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() missing 2 required positional arguments: 'bs_size' and 'alpha'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "An example for SVDD model fitting with negataive samples\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from src.BaseSVDD import BaseSVDD\n",
    "\n",
    "# create 100 points with 2 dimensions\n",
    "# n = 100\n",
    "# dim = 2\n",
    "# X = np.r_[np.random.randn(n, dim)]\n",
    "\n",
    "X = np.array(df_test)\n",
    "\n",
    "# svdd object using rbf kernel\n",
    "svdd = BaseSVDD(C=1.0, gamma=0.129, kernel='rbf', display='on')\n",
    "\n",
    "# fit the SVDD model\n",
    "svdd.fit(X)\n",
    "\n",
    "# predict the label\n",
    "y_predict = svdd.predict(X)\n",
    "\n",
    "# plot the boundary\n",
    "svdd.plot_boundary(X)\n",
    "\n",
    "# plot the distance\n",
    "radius = svdd.radius\n",
    "distance = svdd.get_distance(X)\n",
    "svdd.plot_distance(radius, distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3차원으로 실행하였을 때는 다음과 같다. 이때는 4차원으로 차원을 높이는데 시각화할 수 없으므로, K 관리도 만 그리기로 하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "An example for SVDD model fitting with negataive samples\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/USER/Documents/Jupyter Notebook/public_procurement/Project_02_15\\SVDD-Python-master/\")\n",
    "import numpy as np\n",
    "from src.BaseSVDD import BaseSVDD\n",
    "\n",
    "# create 100 points with 2 dimensions\n",
    "# n = 100\n",
    "# dim = 2\n",
    "# X = np.r_[np.random.randn(n, dim)]\n",
    "\n",
    "X = np.array(df_test_2)\n",
    "\n",
    "# svdd object using rbf kernel\n",
    "svdd = BaseSVDD(C=1.0, gamma=0.15, kernel='rbf', display='on')\n",
    "\n",
    "# fit the SVDD model\n",
    "svdd.fit(X)\n",
    "\n",
    "# predict the label\n",
    "y_predict = svdd.predict(X)\n",
    "\n",
    "# plot the boundary\n",
    "# svdd.plot_boundary(X)\n",
    "\n",
    "# # plot the distance\n",
    "radius = svdd.radius\n",
    "distance = svdd.get_distance(X)\n",
    "svdd.plot_distance(radius, distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSO 는 최적점을 찾아가는 과정으로, 기존 Gradient descent에서 multi-point를 보고 진행하는 것이다.\n",
    "## 이때 주어지는 데이터는 임의로 설정한 데이터이다. X가 input이고, y가 one-class 이다. 여기서 SVDD가 PSO를 통해서  얼마나 잘 이상치를 감지해 나가는지 확인하는 과정이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from src.BaseSVDD import BaseSVDD, BananaDataset\n",
    "from sko.PSO import PSO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Banana-shaped dataset generation and partitioning\n",
    "X, y = BananaDataset.generate(number=100, display='off')\n",
    "X_train, X_test, y_train, y_test = BananaDataset.split(X, y, ratio=0.3)\n",
    "\n",
    "# objective function\n",
    "def objective_func(x):\n",
    "    x1, x2 = x\n",
    "    svdd = BaseSVDD(C=x1, gamma=x2, kernel='rbf', display='off')\n",
    "    y = 1-svdd.fit(X_train, y_train).accuracy\n",
    "    return y\n",
    "\n",
    "# Do PSO\n",
    "pso = PSO(func=objective_func, dim=2, pop=10, max_iter=20, \n",
    "          lb=[0.01, 0.01], ub=[1, 3], w=0.8, c1=0.5, c2=0.5)\n",
    "pso.run()\n",
    "\n",
    "print('best_x is', pso.gbest_x)\n",
    "print('best_y is', pso.gbest_y)\n",
    "\n",
    "# plot the result\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x = pd.DataFrame([i for i in range(len(pso.gbest_y_hist))])[0],y = pd.DataFrame(pso.gbest_y_hist)[0], mode = 'lines+markers'))\n",
    "fig.update_layout(\n",
    "    autosize = False,\n",
    "    width = 800,\n",
    "    height = 800\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from sklearn.datasets import load_wine\n",
    "from src.BaseSVDD import BaseSVDD, BananaDataset\n",
    "\n",
    "# Banana-shaped dataset generation and partitioning\n",
    "X, y = BananaDataset.generate(number=100, display='on')\n",
    "X_train, X_test, y_train, y_test = BananaDataset.split(X, y, ratio=0.3)\n",
    "\n",
    "# \n",
    "svdd = BaseSVDD(C=0.10905555, gamma=0.60239708, kernel='rbf', display='on')\n",
    "\n",
    "# \n",
    "svdd.fit(X_train,  y_train)\n",
    "\n",
    "# \n",
    "svdd.plot_boundary(X_train,  y_train)\n",
    "\n",
    "#\n",
    "y_test_predict = svdd.predict(X_test, y_test)\n",
    "\n",
    "#\n",
    "radius = svdd.radius\n",
    "distance = svdd.get_distance(X_test)\n",
    "svdd.plot_distance(radius, distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCO방식은 Hyper-parameter을 찾는 과정 중에 하나이고, 위는 이 방식을 통해서 찾은 Hyper-parameter을 임의의 데이터(Banana 모양)에 적용시키고, 그에 대해서 Train Data 에 대한 정확도와 Test 데이터에 대한 정확도를 보는 것이다 (KFold 사용 x)\n",
    "\n",
    "## 이번에는 위의 데이터에 대해서 K-Fold 방식으로 정확도를 계산하여 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.BaseSVDD import BaseSVDD, BananaDataset\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Banana-shaped dataset generation and partitioning\n",
    "X, y = BananaDataset.generate(number=100, display='on')\n",
    "X_train, X_test, y_train, y_test = BananaDataset.split(X, y, ratio=0.3)\n",
    "\n",
    "# \n",
    "svdd = BaseSVDD(C=0.9, gamma=0.3, kernel='rbf', display='on')\n",
    "\n",
    "\n",
    "# cross validation (k-fold)\n",
    "k = 5\n",
    "scores = cross_val_score(svdd, X_train, y_train, cv=k, scoring='accuracy')\n",
    "\n",
    "#\n",
    "print(\"Cross validation scores:\")\n",
    "for scores_ in scores:\n",
    "    print(scores_)\n",
    " \n",
    "print(\"Mean cross validation score: {:4f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCO와 다르게, Grid_Search로 (정확도를 performance로 봄) Hyper-parameter을 보도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from sklearn.datasets import load_wine\n",
    "from src.BaseSVDD import BaseSVDD, BananaDataset\n",
    "from sklearn.model_selection import KFold, LeaveOneOut, ShuffleSplit\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "\n",
    "# Banana-shaped dataset generation and partitioning\n",
    "X, y = BananaDataset.generate(number=100, display='off')\n",
    "X_train, X_test, y_train, y_test = BananaDataset.split(X, y, ratio=0.3)\n",
    "\n",
    "param_grid = [\n",
    "    {\"kernel\": [\"rbf\"], \"gamma\": [0.1, 0.2, 0.5], \"C\": [0.1, 0.5, 1]},\n",
    "    {\"kernel\": [\"linear\"], \"C\": [0.1, 0.5, 1]},\n",
    "    {\"kernel\": [\"poly\"], \"C\": [0.1, 0.5, 1], \"degree\": [2, 3, 4, 5]},\n",
    "]\n",
    "\n",
    "svdd = GridSearchCV(BaseSVDD(display='off'), param_grid, cv=5, scoring=\"accuracy\")\n",
    "svdd.fit(X_train, y_train)\n",
    "print(\"best parameters:\")\n",
    "print(svdd.best_params_)\n",
    "print(\"\\n\")\n",
    "\n",
    "# \n",
    "best_model = svdd.best_estimator_\n",
    "means = svdd.cv_results_[\"mean_test_score\"]\n",
    "stds = svdd.cv_results_[\"std_test_score\"]\n",
    "\n",
    "for mean, std, params in zip(means, stds, svdd.cv_results_[\"params\"]):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이번에는 데이터를 plot 시켜보았을 때 비선형 이라면 어떻게 되는지 보고 싶다. KPCA 라는 방법을 사용하였으며, Test, Train으로 나누어지지 않았으므로, Prediction과 Train의 accuracy가 동일하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "from src.BaseSVDD import BaseSVDD\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "\n",
    "# create 100 points with 5 dimensions\n",
    "X = np.r_[np.random.randn(50, 5) + 1, np.random.randn(50, 5)]\n",
    "y = np.append(np.ones((50, 1), dtype=np.int64), \n",
    "              -np.ones((50, 1), dtype=np.int64),\n",
    "              axis=0)\n",
    "\n",
    "# number of the dimensionality\n",
    "kpca = KernelPCA(n_components=2, kernel=\"rbf\", gamma=0.1, fit_inverse_transform=True)\n",
    "X_kpca = kpca.fit_transform(X)\n",
    "\n",
    "# fit the SVDD model\n",
    "svdd = BaseSVDD(C=0.9, gamma=10, kernel='rbf', display='on')\n",
    "\n",
    "# fit and predict\n",
    "svdd.fit(X_kpca,  y)\n",
    "y_test_predict = svdd.predict(X_kpca, y)\n",
    "\n",
    "# plot the distance curve\n",
    "radius = svdd.radius\n",
    "distance = svdd.get_distance(X_kpca)\n",
    "svdd.plot_distance(radius, distance)\n",
    "\n",
    "# plot the boundary\n",
    "svdd.plot_boundary(X_kpca,  y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 임의의 데이터을 기반으로 사용한 모델에 대해서 Confusion matrix 및 ROC 커브를 그려보았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "An example for drawing the confusion matrix and ROC curve\n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.BaseSVDD import BaseSVDD\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# generate data\n",
    "n = 100\n",
    "dim = 5\n",
    "X = np.r_[np.random.randn(n, dim) + 1, np.random.randn(n, dim)]\n",
    "y = np.append(np.ones((n, 1), dtype=np.int64), \n",
    "              -np.ones((n, 1), dtype=np.int64),\n",
    "              axis=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "# SVDD model\n",
    "svdd = BaseSVDD(C=0.12, gamma=0.1, kernel='rbf', display='on')\n",
    "svdd.fit(X_train,  y_train)\n",
    "y_test_predict = svdd.predict(X_test, y_test)\n",
    "\n",
    "# plot the distance curve\n",
    "radius = svdd.radius\n",
    "distance = svdd.get_distance(X_test)\n",
    "svdd.plot_distance(radius, distance)\n",
    "\n",
    "# confusion matrix and ROC curve\n",
    "cm = confusion_matrix(y_test, y_test_predict)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()\n",
    "y_score = svdd.decision_function(X_test)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color=\"darkorange\", lw=3, label=\"ROC curve (area = %0.2f)\" % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color=\"navy\", lw=3, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
